---
title: "Housing Price Prediction Model using modeldata package - a subset of ames housing data"
author: "Saurav Mukherjee"
date: "2023-02-16"
output:
  pdf_document: default
---


```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)

```

# Introduction

I am building home price prediction model. I am using Ames Housing dataset to explore the attributes which have been identified somehow influencing the housing cost.

Initially I wanted to use the 'Ames Housing Data" - a data set describing the sale of individual residential property in Ames, Iowa from 2006 to 2010. The data set contains 2930 observations and a large number of explanatory
variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home
values. Howvever, I looked at a dataset which is a subset of this dataset and which is available within modeldata package created by https://modeldata.tidymodels.org/. 
I did some research and looked at the model - Hedonic Pricing Method to predict the house price. The Hedonic Pricing Method talks about internal characteristics as well as the external factors affecting the price of a good. Based on the idea of hedonic price modeling I am looking the is that neighborhood-specific and unit-specific characteristics help determine house prices.


## Data - Ames Housing Data

A data set from De Cock (2011) has 82 fields were recorded for 2,930 properties in Ames IA. I used a version from the package modeldata dataset name as ames which is copies from the original AmesHousing package but does not include a few quality columns that appear to be outcomes rather than predictors.


## Load required Libraries
## Load ames dataset
## Setup environments


```{r, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(here)) install.packages("here", repos = "http://cran.us.r-project.org")
if(!require(rstudioapi)) install.packages("rstudioapi", repos = "http://cran.us.r-project.org")
if(!require(broom)) install.packages("broom", repos = "http://cran.us.r-project.org")
if(!require(modeldata)) install.packages("modeldata", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(moments)) install.packages("moments", repos = "http://cran.us.r-project.org")
if(!require(corrr)) install.packages("corrr", repos = "http://cran.us.r-project.org")
#if(!require(tidymodels)) install.packages("tidymodels", repos = "http://cran.us.r-project.org")
#if(!require(lares)) install.packages("lares", repos = "http://cran.us.r-project.org")
if(!require(GGally)) install.packages("GGally", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(lubridate)
library(dplyr)
library(here)
library(rstudioapi)
library(broom)
library(modeldata)
library(ggplot2)
library(moments)
library(GGally)
library(corrr)
library(randomForest)

# Load ames Dataset
data(ames)

# To make graphs more readable disabling scientific notation
options(scipen = 100)

# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path 
#setwd(dirname(current_path ))

options(timeout = 120)

options(repr.plot.width = 4, repr.plot.height =4)

```



# Exploratory Data Analysis

## Explore Ame Dataset - Dimension, Columns and Datatypes

## Explore Sales Price Distribution 

```{r , echo = FALSE, message = FALSE, warning = FALSE}
############### Data Exploration and Visualization


knitr::kable(dim(ames),caption = "Ames Housing Dataset dimension")

print("Ames Housing Dataset Columns")
colnames(ames)

knitr::kable(str(ames),caption = "Ames Housing Dataset")

# Sale Price Characteristics 

ames %>% 
  ggplot(aes(Sale_Price)) + 
    geom_histogram(aes(y = ..density..),
                   colour = 1, fill = "black") +
  labs(title = "Distribution of house prices", x = "Price($)", y = "Frequency") +
  geom_density() +
  theme_minimal()

# The distribution of SalePrice is right-skewed. Let's check its Skewness and Kurtosis statistics.

```
## Sale Price Observation
The Sale Price is right-skewed 
```{r , echo = FALSE, message = FALSE, warning = FALSE}
# The distribution of SalePrice is right-skewed. Let's check its Skewness and Kurtosis statistics.
cat("\nSale Price skewness :", skewness(ames$Sale_Price))
cat("\nSale Price kurtosis :", kurtosis(ames$Sale_Price))
```

## Houses and Year Built


```{r , echo = FALSE, message = FALSE, warning = FALSE}
ames %>%
  ggplot(aes(Year_Built)) +
  geom_bar(color = "black") +
#  scale_x_continuous() +
 # scale_x_discrete(breaks = 10)  +
  labs(title = "Year Built", x = "Year Built", y = "No of Houses") 

```
It looks that we have more houses were built at the beginning of 2000.

## Condition of the houses

```{r , echo = FALSE, message = FALSE, warning = FALSE, fig.align="center", fig.width = 14}
ames %>%
  ggplot(aes(Overall_Cond)) +
  geom_bar(color = "black") +
  labs(title = "Overall Condition of the houses", x = "Overall Cond.", y = "No of Houses")

```
House condition - most of the houses are of average condition

## Neighborhood and House Price

```{r , echo = FALSE, message = FALSE, warning = FALSE, fig.align="center", fig.width = 14}
ames %>% ggplot(aes(x = Neighborhood, y = Sale_Price)) +
  geom_boxplot() +
  ylab("Sale Price") +
  xlab("Neighbothood") +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust=1))

```
House Price varies with the neighborhood with few outliers by neighborhood. Also, the median house price by neighborhood is roughly between 200,000 and 400,000. It seems Neighborhood would have some impact on housing price.


# Correlation between Sale Price and other variables  

## Correlation between numeric variables

```{r , echo = FALSE, message = FALSE, warning = FALSE}
  
  ames_num <- ames %>% select_if(~is.numeric(.x)) 
  
  
  ames_num %>% ggcorr() +
              ggplot2::labs(title = "Correlation between Numeric Variables")
  

```

There are some high correlations between variables mostly positive but with some negative. I did further analysis and added pairwise correlation between other numeric variables and sales price. 

## Correlation of Sales Price with other numeric variables
```{r , echo = FALSE, message = FALSE, warning = FALSE}
  # Correlation of Sales Price with other numeric variables
  
  var_cors <- sapply(ames_num, function(var){
    var_cor <- cor(ames$Sale_Price,var )
    return(var_cor)
  })
  

  knitr::kable(var_cors,caption = "Ames Housing Dataset - correlated numeric variables with the Sale Price")
```


Thus, I identified variables which has higher correlations (correlation > 0.5 and < - 0.2) 

I also looked at some non-numeric variables and their relatins with the Sale Price

#### Correlation of Sales Price with non-numeric variables
```{r , echo = FALSE, message = FALSE, warning = FALSE}
  # Correlation of Sales Price with other non-numeric variables
  
  ames_nonnum <- ames %>% select(where(~!is.numeric(.x) ))
  
  
  var_cors <- sapply(ames_nonnum, function(var){
    var_cor <- cor(ames$Sale_Price,rank(var) )
    return(var_cor)
  })
  
  knitr::kable(var_cors,caption = "Ames Housing Dataset - correlated non-numeric variables with the Sale Price")


```

## Looking at the non-numeric variable, I identified few variables which are highly correlated - 
  MS_Zoning, Lot_Shape, Foundation, Sale_Condition , Garage_Finish, House_Style, Heating_QC, 
  
# Feature Engineering and additional visualizations

## Created a variable total_area = First_Flr_SF + Second_Flr_SF + Total_Bsmt_SF 
## Created a variable total_Bathroom = Full_Bath + Bsmt_Full_Bath + 0.5* Half_Bath+ 0.5 * Bsmt_Half_Bath 
## Created a variable orarall_Condition_n a numeric representation of overall_Condition
## Created a variable house_Age = year_Sold - year_Build
```{r , echo = FALSE, message = FALSE, warning = FALSE}
ames <- ames %>%
  mutate(total_Area = First_Flr_SF + Second_Flr_SF + Total_Bsmt_SF )


cat("\nCorelation between Total Area and Sale Price :", cor(ames$total_Area,ames$Sale_Price))


# Total_Bathroom considering full bath and half bath
ames <- ames %>%
  mutate(total_Bathroom =  Full_Bath + Bsmt_Full_Bath + 0.5* Half_Bath+ 0.5 * Bsmt_Half_Bath)

cat("\nCorelation between Total Bathroom and Sale Price :", cor(ames$total_Bathroom,ames$Sale_Price))

# Age of the house 
ames <- ames %>%
  mutate(house_Age =  Year_Sold - Year_Built)

cat("\nCorelation between Age of House and Sale Price :",  cor(ames$house_Age,ames$Sale_Price))



### Overall Condition
#Levels: Very_Poor Poor Fair Below_Average Average Above_Average Good Very_Good Excellent Very_Excellent

ames <- ames %>%
  mutate(Overall_Cond_n = dplyr::recode(
    Overall_Cond,
    "Very_Excellent" = 10,
    "Excellent" = 9,
    "Very_Good" = 8,
    "Good" = 7,
    "Above_Average" = 6,
    "Average" = 5,
    "Below_Average" =4,
    "Fair" = 3,
    "Poor" = 2,
    "Very_Poor" =1
  )) 

cat("\nCorelation between Overall Condition and Sale Price :", cor(ames$Sale_Price,ames$Overall_Cond_n))



# Total area
ames %>% 
  ggplot(aes(total_Area)) + 
  geom_histogram(bins = 25, color = "black") + 
  #scale_x_log10() + 
  scale_x_continuous() +
  labs(title = "Distribution of Area", x = "Area (sqft)", y = "Frequency") +
  theme_minimal()


### Linear 
# Total Area vs. Price
ames %>%
  ggplot(aes(total_Area,Sale_Price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(title = "Total Area vs. Sales Price", x = "Total Area (sqft)", y = "Sale Price ($)")


# Age of the House vs. Price

ames %>%
  ggplot(aes(house_Age ,Sale_Price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(title = "Age of the house vs. Sales Price", x = "Age", y = "Sale Price ($)")



# Overall Condition vs. Price

ames %>%
  ggplot(aes(Overall_Cond_n,Sale_Price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(title = "Overall Condition vs. Sales Price", x = "Overall Condition", y = "Sale Price ($)")

```
Looking at the negative correlation between overall condition of the house and sales price I felt that there is something incorrect about the data. I excluded the overall condition from the final parameter set  
# Create Final Set with Parameters
## Numeric - 
Sale_Price,total_Area, Gr_Liv_Area, house_Age, total_Bathroom ,Garage_Cars,Garage_Area,
                         Year_Remod_Add, Mas_Vnr_Area,  
## Non-Numeric -
House Attributes - Lot_Shape, Foundation, Sale_Condition , Garage_Finish, House_Style, Heating_QC, 
External Attributes - MS_Zoning, Neighborhood

```{r , echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}
ames <- ames %>% select (Sale_Price,total_Area, Gr_Liv_Area, house_Age, total_Bathroom ,Garage_Cars,Garage_Area,
                         Year_Remod_Add, Mas_Vnr_Area,  Lot_Shape, Foundation, Sale_Condition , Garage_Finish,    House_Style, Heating_QC, MS_Zoning, Neighborhood  )

ames %>% ggcorr(size = 3, label = TRUE, label_size = 4, label_round = 2, label_alpha = TRUE) +
  ggplot2::labs(title = "Correlation between Numeric Variables of the Final Attribute Sets")

```


# Create Test Set and Training set for building Linear Models
## Test set will be 20% of housing_data data
```{r , echo = FALSE, message = FALSE, warning = FALSE}
set.seed(2023, sample.kind="Rounding")
test_index <- createDataPartition(y = ames$Sale_Price, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- ames[-test_index,]
test_set <- ames[test_index,]

knitr::kable(dim(ames),caption = "Ames Housing Dataset dimension")


knitr::kable(summary(ames), caption = "Ames Housing Dataset Summary")

```
# House Price Prediction Model - develop, train and test

# Average House Price

## Build Linear Models
I started with linear model and some selected set of parameters/attributes and evaluated the performaces of the models use RMSE.
In the first Linear Model we used "Age of the House" and "Total Bathroom"
I enhanced the model and added "Age of the House", Garage_Cars + Garage_Area + Year_Remod_Add + Mas_Vnr_Area
```{r , echo = FALSE, message = FALSE, warning = FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2, na.rm = TRUE))
}


# Calculate the overall average rating across all movies included in the training set

mu_hat <- mean(train_set$Sale_Price)


# Calculate RMSE based on naive model
naive_rmse <- round(RMSE(test_set$Sale_Price, mu_hat),2)
rmse_results <- tibble(method = "Just the average: ", RMSE = naive_rmse)
cat("\nNaive RMSE in ,000 :",naive_rmse)

```
## 1st Leaner Model - Sale Price ~ total area + total bathroom
Build the model using training set data
Predict the Sale Prices of the test set
Calculate RMSA
```{r , echo = FALSE, message = FALSE, warning = FALSE}
# Linear Model Sale Price ~ total area + total bathroom 


#head(train_set)

model_ln1 <- train_set %>%
  lm(Sale_Price ~ total_Area + total_Bathroom , data = .)

y_hat <- predict(model_ln1, newdata = test_set)

#RMSE(test_set$Sale_Price,y_hat)

summary(model_ln1)


# Calculate RMSE based on area effects
model_rmse <- RMSE(test_set$Sale_Price,y_hat)
rmse_results <- bind_rows(rmse_results,
                          tibble(method="Linear Model based on Total Area and Total Bathroom: ",
                                     RMSE = model_rmse ))


```
## 1st Linear Model coefficients and RMSE
```{r , echo = FALSE, message = FALSE, warning = FALSE}
rmse_results %>% knitr::kable()
model_ln1$coefficients 

# Estimate age of house effect along with total area  effect
```

## Second Linear Model using all selected Numeric Attributes

```{r , echo = FALSE, message = FALSE, warning = FALSE}

model_ln2 <- ames %>%
  lm(Sale_Price ~ total_Area +total_Bathroom + house_Age + Garage_Cars + Garage_Area +
     Year_Remod_Add +Mas_Vnr_Area, data = .)

y_hat <- predict(model_ln2, newdata = test_set)

RMSE(test_set$Sale_Price,y_hat)


tidy(model_ln2, conf.int = TRUE)

summary(model_ln2)


# Calculate RMSE based on numeric attributes
model_rmse <- RMSE(test_set$Sale_Price,y_hat)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Linear Model based on selected Numeric attributes of the dataset: ",  
                                     RMSE = model_rmse ))


```


With linear model and with a set of attributes I was able to tune the model and reduce RMSE.

# Final Linear Model coefficients and model improvements
```{r , echo = FALSE, message = FALSE, warning = FALSE}
rmse_results %>% knitr::kable()

model_ln2$coefficients 
```


# Non-linear Models
I wanted to further tune the model and enhance the accuracy. I planned to use "kNN", "Classification and regression trees (CART)" and Random Forrest. I added the non-linear parameters with the linear ones. Some of the non-linear ones are attributes of the house and some are external 
External attributes - Zoning and Neighborhood

## k Nearest Neighbor (kNN) Model
Build th model and find out the predicted Sale Prices
Calculate RMSE

```{r , echo = FALSE, message = FALSE, warning = FALSE}
## K Nearest Neighbor 


train_knn <- train(Sale_Price ~ ., method = "knn",
                   data = train_set,
                   tuneGrid = data.frame(k = seq(9, 71, 2)))

summary(train_knn)

ggplot(train_knn, highlight = TRUE) +
  labs(title = "Knn Model Cross Validation")

y_hat <- round(predict(train_knn, test_set, type = "raw"))

# Calculate RMSE based on Knn Model
model_rmse <- RMSE(test_set$Sale_Price,y_hat)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Knn Model: ",  
                                 RMSE = model_rmse ))
rmse_results %>% knitr::kable()


#confusionMatrix(factor(y_hat,levels=1:490),factor(test_set$Sale_Price,levels=1:490))$overall["Accuracy"]


```
Next I am using Classification and regression trees (CART) model to see whether it reduces the RMSE value

# Using Model - Classification and regression trees (CART)
Build th model and find out the predicted Sale Prices
Calculate RMSE

```{r , echo = FALSE, message = FALSE, warning = FALSE}

# fit a classification tree and plot it
train_rpart <- train(Sale_Price ~ .,
                     method = "rpart",
                     tuneGrid = data.frame(cp = seq(0.0, 0.1, len = 25)),
                     data = train_set)
ggplot(train_rpart) +
  labs(title = "CART Model Cross Validation")

#predict(train_rpart, test_set)

y_hat <- round(predict(train_rpart, test_set))


# Calculate RMSE based on Classification and regression trees (CART)
model_rmse <- RMSE(test_set$Sale_Price,y_hat)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Classification and regression trees (CART) Model: ",  
                                 RMSE = model_rmse ))
rmse_results %>% knitr::kable()



```

# Random Forrest -

Train the model and find out the predicted Sale Prices
Calculate RMSE

```{r , echo = FALSE, message = FALSE, warning = FALSE}
# Random Forrest

train_rf <- randomForest(Sale_Price ~ ., data=train_set)

print("Error vs. Trees")

plot(train_rf)


y_hat <- predict(train_rf, test_set)

# Calculate RMSE based on Random Forrest Model
model_rmse <- RMSE(test_set$Sale_Price,y_hat)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Random Forrest Model: ",  
                                 RMSE = model_rmse ))
rmse_results %>% knitr::kable()

#confusionMatrix(factor(y_hat,levels=1:490),factor(test_set$Sale_Price,levels=1:490))$overall["Accuracy"]
```



I got the best result when I used the Classification and regression trees (CART). I wanted to use the Confusion Matrix to calculate the accuracy for in the case of kNN and Classification and regression trees (CART). But because Sale Price is a continuous variable, I could not use Confusion Matrix function directly. When I converted Sale Price ( both predicted and original) into factor, I got extremely low accuracy. After doing further research I found out that this is not a ideal situation to use Confusion Matrix to calculate the accuracy.


# Final Result and Model Performances

RMSEs over Models


```{r , echo = FALSE, message = FALSE, warning = FALSE}
rmse_results %>% knitr::kable()

```


# Conclusion 
To build the House Price Prediction model I started with building Linear model with a set of numeric variables. I identified those variables by observing strong correlation with the "Sale Price"
## Parameters used in the Linear Model 
Sale_Price,total_Area, Gr_Liv_Area, house_Age, total_Bathroom ,Garage_Cars,Garage_Area, Year_Remod_Add,  Mas_Vnr_Area
I used RMSE to calculate the efficiency 

Next to reduce th error margin , I looked at three other Models kNN, Classification and regression trees (CART) and Random Forrest. I identified some non-numeric attributes looking at their correlation with the Sale Price 
## Non-Numeric -
House Attributes - Lot_Shape, Foundation, Sale_Condition , Garage_Finish, House_Style, Heating_QC, 
External Attributes - MS_Zoning, Neighborhood

Finally with Random Forrest Model I got the lowest RMSE. 

I am sure doing some additional Feature Engineering and combining more than one models I will be able to build a better House Prediction Model.  



# Reference -
Introduction to Data Science by Rafael A. Irizarry

https://jse.amstat.org/v19n3/decock.pdf - Ames, Iowa: Alternative to the Boston Housing Data as an
End of Semester Regression Project - Dean De Cock

https://modeldata.tidymodels.org/reference/ames.html - Ames Housing Data

https://www.investopedia.com





